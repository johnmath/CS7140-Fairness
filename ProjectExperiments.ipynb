{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sbn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from utils import DataUtils\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import DataUtils\n",
    "from CS7140_balancers import BinaryBalancer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and train the MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = DataUtils.load_adults(use_torch_dataset=False, test=0.25)\n",
    "\n",
    "\n",
    "hidden_layer_sizes = (128)\n",
    "model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, \n",
    "                      learning_rate_init=.003, \n",
    "                      verbose=True, \n",
    "                      learning_rate=\"adaptive\", \n",
    "                      max_iter=300)\n",
    "\n",
    "\n",
    "trained_model = model.fit(X=df_train.loc[:, df_train.columns != \"output\"], \n",
    "                          y=df_train[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Sensitive Attribute and Report Overall Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"native-country\", \"race\", \"sex\", \"workclass\"]\n",
    "targets = [\"Mexico\", \"Black\", \"Female\", \"Private\"]\n",
    "\n",
    "Y_accs = []\n",
    "Y_adj_accs = []\n",
    "for attribute in zip(categories, targets):\n",
    "    \n",
    "    category = attribute[0]\n",
    "    sensitive_attribute = attribute[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "\n",
    "    y_pred =  trained_model.predict(df_test.loc[:, df_train.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "    acc = sum(y_pred == y_true)/len(y_pred)\n",
    "    print(f\"The model's overall accuracy is {acc*100:.4}%\")\n",
    "    Y_accs.append(acc)\n",
    "    \n",
    "    # Fit balancer to adjust the predictions\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "    fair_acc = sum(pb.get_adjusted_predictions() == y_true)/len(y_true)\n",
    "    print(f\"The model's overall accuracy after adjustment is {fair_acc*100:.4}%\\n\")\n",
    "    Y_adj_accs.append(fair_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(categories) + 1)\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes = [\"No \\nAdjustment\"] + [categories[i] + \"=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Utility\", fontdict=title_font)\n",
    "plt.bar(x, [Y_accs[0]] + Y_adj_accs, color=[\"darkgrey\", \"dodgerblue\", \"coral\", \"khaki\", \"mediumseagreen\"])\n",
    "\n",
    "plt.xticks(x, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Overall Prediction Accuracy\", fontdict=label_font)\n",
    "\n",
    "\n",
    "plt.ylim(0,1)\n",
    "ax = plt.gca()\n",
    "ax.autoscale(False)\n",
    "ax.plot(plt.gca().get_xlim(), [Y_accs[0], Y_accs[0]], c=\"r\", linestyle=\"--\")\n",
    "plt.draw()\n",
    "\n",
    "#plt.savefig(\"Figures/overall_accuracies.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Sensitive Attribute and Report Per-Subgroup Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_accs_on_group = []\n",
    "Y_adj_accs_on_group = []\n",
    "proportion_of_dataset = []\n",
    "for attribute in zip(categories, targets):\n",
    "    \n",
    "    category = attribute[0]\n",
    "    sensitive_attribute = attribute[1]\n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    proportion_of_dataset.append(frequency)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "\n",
    "    y_pred =  trained_model.predict(df_test.loc[:, df_train.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "    \n",
    "    a_bool = a.astype(bool)\n",
    "\n",
    "    group_acc = sum(y_pred[a_bool] == y_true[a_bool])/len(y_pred[a_bool])\n",
    "    print(f\"The model's loss on this group (0) is {1 - group_acc:.4}\")\n",
    "    Y_accs_on_group.append(group_acc)\n",
    "    # Fit balancer to adjust the predictions\n",
    "#     print(\"Before Adjustment\\n\", confusion_matrix(y_true[a_bool], y_pred[a_bool]), \"\\n-----\")\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "    y_adj = pb.get_adjusted_predictions()\n",
    "    fair_group_acc = sum(y_adj[a_bool] == y_true[a_bool])/len(y_true[a_bool])\n",
    "    Y_adj_accs_on_group.append(fair_group_acc)\n",
    "#     print(\"After Adjustment\\n\", confusion_matrix(y_true[a_bool], y_adj[a_bool]), \"\\n-------\")\n",
    "    print(f\"The model's loss on this group (0) after adjustment is {1 - fair_group_acc:.4}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes =[categories[i] + \"=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Utility\", fontdict=title_font)\n",
    "plt.bar(x - width,  Y_accs_on_group, width = width, color=\"dodgerblue\")\n",
    "plt.bar(x, Y_adj_accs_on_group, width = width, color=\"coral\")\n",
    "\n",
    "plt.xticks(x - width/2, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Prediction Accuracy on Sensitive Group\", fontdict=label_font)\n",
    "plt.legend([\"Original Model ($\\hat{Y}$)\", \"Adjusted Model ($Y^{*}$)\"], loc=\"lower right\")\n",
    "plt.savefig(\"Figures/subgroup_acuracy.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Calibration Statistics before and after adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Y0 = []\n",
    "C_Yhat0 = []\n",
    "C_Ystar0 = []\n",
    "\n",
    "C_Y1 = []\n",
    "C_Yhat1 = []\n",
    "C_Ystar1 = []\n",
    "\n",
    "for attribute in zip(categories, targets):\n",
    "    category = attribute[0]\n",
    "    sensitive_attribute = attribute[1]\n",
    "\n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "\n",
    "    y_pred =  trained_model.predict(df_test.loc[:, df_train.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "\n",
    "    # Fit balancer to adjust the predictions\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "\n",
    "    calibration_table, _ = pb.summary(return_stats=True)\n",
    "    \n",
    "    # 0 is not the sensitive attrbibute\n",
    "    C_Y0.append(calibration_table[0].loc[\"Fraction where Y = 1\"])\n",
    "    C_Yhat0.append(calibration_table[0].loc[\"Fraction where Y_ = 1\"])\n",
    "    C_Ystar0.append(calibration_table[0].loc[\"Fraction where Y* = 1\"])\n",
    "    \n",
    "    # 1 is the sensitive attribute\n",
    "    C_Y1.append(calibration_table[1].loc[\"Fraction where Y = 1\"])\n",
    "    C_Yhat1.append(calibration_table[1].loc[\"Fraction where Y_ = 1\"])\n",
    "    C_Ystar1.append(calibration_table[1].loc[\"Fraction where Y* = 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1.5, 3, 4.5])\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes =[categories[i] + \"=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Calibration (Sensitive Group)\", fontdict=title_font)\n",
    "plt.bar(x - width,  C_Y1, width = width, color=\"dodgerblue\")\n",
    "plt.bar(x, C_Yhat1, width = width, color=\"coral\")\n",
    "plt.bar(x + width, C_Ystar1 ,width=width, color=\"mediumseagreen\")\n",
    "\n",
    "plt.xticks(x, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Fraction of Positive Label\", fontdict=label_font)\n",
    "plt.legend([\"True Labels ($Y$)\", \"Original Model ($\\hat{Y}$)\", \"Adjusted Model ($Y^{*}$)\"], loc=\"upper left\")\n",
    "plt.savefig(\"Figures/calibration-sensitive.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1.5, 3, 4.5])\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes =[categories[i] + \"!=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Calibration (Non-sensitive Group)\", fontdict=title_font)\n",
    "plt.bar(x - width,  C_Y0, width = width, color=\"dodgerblue\")\n",
    "plt.bar(x, C_Yhat0, width = width, color=\"coral\")\n",
    "plt.bar(x + width, C_Ystar0 ,width=width, color=\"mediumseagreen\")\n",
    "\n",
    "plt.xticks(x, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Fraction of Positive Label\", fontdict=label_font)\n",
    "plt.legend([\"True Labels ($Y$)\", \"Original Model ($\\hat{Y}$)\", \"Adjusted Model ($Y^{*}$)\"], loc=\"lower right\")\n",
    "plt.savefig(\"Figures/calibration-nonsensitive.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration vs Model Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Y_MC = []\n",
    "C_Yhat_MC = []\n",
    "C_Ystar_MC = []\n",
    "\n",
    "Y_acc_MC = []\n",
    "Y_acc_adj_MC = []\n",
    "\n",
    "category = \"sex\"\n",
    "sensitive_attribute = \"Female\"\n",
    "\n",
    "layer_sizes = [(1), (64), (128, 64, 32), (1024, 512, 256, 128, 64)]\n",
    "\n",
    "for layers in layer_sizes:\n",
    "    \n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "    \n",
    "    \n",
    "    new_model = MLPClassifier(hidden_layer_sizes=layers, \n",
    "                              learning_rate_init=.003, \n",
    "                              verbose=True, \n",
    "                              learning_rate=\"adaptive\", \n",
    "                              max_iter=300)\n",
    "    \n",
    "    new_model = new_model.fit(df_train.loc[:, df_train.columns != \"output\"], df_train[\"output\"])\n",
    "    \n",
    "    y_pred =  new_model.predict(df_test.loc[:, df_train.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "    Y_acc_adj_MC.append(sum(y_true == y_pred)/len(y_true))\n",
    "    \n",
    "    # Fit balancer to adjust the predictions\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "\n",
    "    calibration_table, _ = pb.summary(return_stats=True)\n",
    "    \n",
    "    Y_acc_adj_MC.append(sum(y_true == y_adj)/len(y_true))\n",
    "    # 1 is the sensitive attribute\n",
    "    C_Y_MC.append(calibration_table[1].loc[\"Fraction where Y = 1\"])\n",
    "    C_Yhat_MC.append(calibration_table[1].loc[\"Fraction where Y_ = 1\"])\n",
    "    C_Ystar_MC.append(calibration_table[1].loc[\"Fraction where Y* = 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1.5, 3, 4.5])\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Calibration (vs Model Complexity)\", fontdict=title_font)\n",
    "# plot data in grouped manner of bar type\n",
    "plt.bar(x - width,  C_Y_MC, width = width, color=\"dodgerblue\")\n",
    "plt.bar(x, C_Yhat_MC, width = width, color=\"coral\")\n",
    "plt.bar(x + width, C_Ystar_MC, width=width, color=\"mediumseagreen\")\n",
    "\n",
    "plt.xticks(x, [\"[1]\", \"[64]\", \"[128, 64, 32]\", \"[1024, 512, 256, \\n128, 64]\"])\n",
    "plt.xlabel(\"Hidden Layer Sizes\", fontdict=label_font)\n",
    "plt.ylabel(\"Fraction of Positive Label\", fontdict=label_font)\n",
    "plt.legend([\"True Labels ($Y$)\", \"Original Model ($\\hat{Y}$)\", \"Adjusted Model ($Y^{*}$)\"], loc=\"upper left\")\n",
    "plt.savefig(\"Figures/calibration-nonsensitive-complexity.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_accs_on_group = []\n",
    "Y_adj_accs_on_group = []\n",
    "proportion_of_dataset = []\n",
    "for attribute in zip(categories, targets):\n",
    "    \n",
    "    category = attribute[0]\n",
    "    sensitive_attribute = attribute[1]\n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    proportion_of_dataset.append(frequency)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "\n",
    "    y_pred =  new_model.predict(df_test.loc[:, df_test.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "    \n",
    "    a_bool = a.astype(bool)\n",
    "\n",
    "    group_acc = sum(y_pred[a_bool] == y_true[a_bool])/len(y_pred[a_bool])\n",
    "    print(f\"The model's loss on this group (0) is {1 - group_acc:.4}\")\n",
    "    Y_accs_on_group.append(group_acc)\n",
    "    # Fit balancer to adjust the predictions\n",
    "#     print(\"Before Adjustment\\n\", confusion_matrix(y_true[a_bool], y_pred[a_bool]), \"\\n-----\")\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "    y_adj = pb.get_adjusted_predictions()\n",
    "    fair_group_acc = sum(y_adj[a_bool] == y_true[a_bool])/len(y_true[a_bool])\n",
    "    Y_adj_accs_on_group.append(fair_group_acc)\n",
    "#     print(\"After Adjustment\\n\", confusion_matrix(y_true[a_bool], y_adj[a_bool]), \"\\n-------\")\n",
    "    print(f\"The model's loss on this group (0) after adjustment is {1 - fair_group_acc:.4}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "x = np.arange(len(categories))\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes =[categories[i] + \"=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Utility (Overparameterized Model)\", fontdict=title_font)\n",
    "# plot data in grouped manner of bar type\n",
    "plt.bar(x - width,  Y_accs_on_group, width = width, color=\"dodgerblue\")\n",
    "plt.bar(x, Y_adj_accs_on_group, width = width, color=\"coral\")\n",
    "\n",
    "plt.xticks(x - width/2, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Prediction Accuracy on Sensitive Group\", fontdict=label_font)\n",
    "plt.legend([\"Original Model ($\\hat{Y}$)\", \"Adjusted Model ($Y^{*}$)\"], loc=\"lower right\")\n",
    "# plt.savefig(\"Figures/subgroup_accuracy_overparameterized.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"native-country\", \"race\", \"sex\", \"workclass\"]\n",
    "targets = [\"Mexico\", \"Black\", \"Female\", \"Private\"]\n",
    "\n",
    "Y_accs = []\n",
    "Y_adj_accs = []\n",
    "for attribute in zip(categories, targets):\n",
    "    \n",
    "    category = attribute[0]\n",
    "    sensitive_attribute = attribute[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    frequency = sum(df_train[category + \"_ \" + sensitive_attribute])/len(df_train)\n",
    "    print(f\"People with {category}={sensitive_attribute} account for {frequency*100:.4}% of the training data\")\n",
    "    a = np.array(df_test[category + \"_ \" + sensitive_attribute])\n",
    "\n",
    "    y_pred =  new_model.predict(df_test.loc[:, df_train.columns != \"output\"])\n",
    "    y_true = np.array(df_test[\"output\"])\n",
    "    acc = sum(y_pred == y_true)/len(y_pred)\n",
    "    print(f\"The model's overall accuracy is {acc*100:.4}%\")\n",
    "    Y_accs.append(acc)\n",
    "    \n",
    "    # Fit balancer to adjust the predictions\n",
    "    pb = BinaryBalancer(y=y_true, y_=y_pred, a=a, summary=False)\n",
    "    pb.adjust(goal='odds', summary=False)\n",
    "    fair_acc = sum(pb.get_adjusted_predictions() == y_true)/len(y_true)\n",
    "    print(f\"The model's overall accuracy after adjustment is {fair_acc*100:.4}%\\n\")\n",
    "    Y_adj_accs.append(fair_acc)\n",
    "\n",
    "    \n",
    "x = np.arange(len(categories) + 1)\n",
    "width = 0.4\n",
    "label_font = {\n",
    "    'color':  'k',\n",
    "    'weight': 'heavy',\n",
    "    'size': 10\n",
    "}\n",
    "\n",
    "title_font = {\n",
    "    'color':  'k',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "attributes = [\"No \\nAdjustment\"] + [categories[i] + \"=\\n\" + targets[i] for i in range(len(categories))]\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "plt.title(\"Impact of Fairness Adjustment on Utility (Overparameterized Model)\", fontdict=title_font)\n",
    "plt.bar(x, [Y_accs[0]] + Y_adj_accs, color=[\"darkgrey\", \"dodgerblue\", \"coral\", \"khaki\", \"mediumseagreen\"])\n",
    "\n",
    "plt.xticks(x, attributes)\n",
    "plt.xlabel(\"Sensitive Group Adjusted For\", fontdict=label_font)\n",
    "plt.ylabel(\"Overall Prediction Accuracy\", fontdict=label_font)\n",
    "\n",
    "\n",
    "plt.ylim(0,1)\n",
    "ax = plt.gca()\n",
    "ax.autoscale(False)\n",
    "ax.plot(plt.gca().get_xlim(), [Y_accs[0], Y_accs[0]], c=\"r\", linestyle=\"--\")\n",
    "plt.draw()\n",
    "# plt.savefig(\"Figures/overall_accuracy_overparameterized.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
